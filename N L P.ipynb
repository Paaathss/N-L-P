{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMdAgd2pE3IXCjncmuO88oJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**NATURAL LANGUAGE PREPROCESSING (N L P)**"],"metadata":{"id":"0JKPo_-hDS3_"}},{"cell_type":"markdown","source":["**Natural language processing (NLP)** is a branch of artificial intelligence **(Al)** that enables computers to comprehend, generate, and manipulate human language. Natural language processing has the ability to interrogate the **data with natural language text or voice.**\n"],"metadata":{"id":"kyVGpELQDu9a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6_F1K6TDP-e"},"outputs":[],"source":["import nltk"]},{"cell_type":"code","source":["help(nltk)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XH6IoTgWOouN","executionInfo":{"status":"ok","timestamp":1732603769788,"user_tz":-330,"elapsed":494,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"cf485de6-0384-4376-c192-365a9430ef9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Help on package nltk:\n","\n","NAME\n","    nltk\n","\n","DESCRIPTION\n","    The Natural Language Toolkit (NLTK) is an open source Python library\n","    for Natural Language Processing.  A free online book is available.\n","    (If you use the library for academic research, please cite the book.)\n","    \n","    Steven Bird, Ewan Klein, and Edward Loper (2009).\n","    Natural Language Processing with Python.  O'Reilly Media Inc.\n","    https://www.nltk.org/book/\n","    \n","    isort:skip_file\n","    \n","    @version: 3.9.1\n","\n","PACKAGE CONTENTS\n","    app (package)\n","    book\n","    ccg (package)\n","    chat (package)\n","    chunk (package)\n","    classify (package)\n","    cli\n","    cluster (package)\n","    collections\n","    collocations\n","    compat\n","    corpus (package)\n","    data\n","    decorators\n","    downloader\n","    draw (package)\n","    featstruct\n","    grammar\n","    help\n","    inference (package)\n","    internals\n","    jsontags\n","    langnames\n","    lazyimport\n","    lm (package)\n","    metrics (package)\n","    misc (package)\n","    parse (package)\n","    probability\n","    sem (package)\n","    sentiment (package)\n","    stem (package)\n","    tabdata\n","    tag (package)\n","    tbl (package)\n","    test (package)\n","    text\n","    tgrep\n","    tokenize (package)\n","    toolbox\n","    translate (package)\n","    tree (package)\n","    treeprettyprinter\n","    treetransforms\n","    twitter (package)\n","    util\n","    wsd\n","\n","SUBMODULES\n","    agreement\n","    aline\n","    api\n","    arlstem\n","    arlstem2\n","    association\n","    bleu_score\n","    bllip\n","    boxer\n","    brill\n","    brill_trainer\n","    casual\n","    chart\n","    chrf_score\n","    cistem\n","    confusionmatrix\n","    corenlp\n","    crf\n","    decisiontree\n","    dependencygraph\n","    destructive\n","    discourse\n","    distance\n","    drt\n","    earleychart\n","    evaluate\n","    featurechart\n","    gale_church\n","    gdfa\n","    gleu_score\n","    glue\n","    hmm\n","    hunpos\n","    ibm1\n","    ibm2\n","    ibm3\n","    ibm4\n","    ibm5\n","    ibm_model\n","    isri\n","    lancaster\n","    legality_principle\n","    lfg\n","    linearlogic\n","    logic\n","    mace\n","    malt\n","    mapping\n","    maxent\n","    megam\n","    meteor_score\n","    mwe\n","    naivebayes\n","    named_entity\n","    nist_score\n","    nonprojectivedependencyparser\n","    paice\n","    pchart\n","    perceptron\n","    phrase_based\n","    porter\n","    positivenaivebayes\n","    projectivedependencyparser\n","    prover9\n","    punkt\n","    recursivedescent\n","    regexp\n","    relextract\n","    repp\n","    resolution\n","    ribes_score\n","    rslp\n","    rte_classify\n","    scikitlearn\n","    scores\n","    segmentation\n","    senna\n","    sequential\n","    sexpr\n","    shiftreduce\n","    simple\n","    snowball\n","    sonority_sequencing\n","    spearman\n","    stack_decoder\n","    stanford\n","    stanford_segmenter\n","    tableau\n","    tadm\n","    textcat\n","    texttiling\n","    tnt\n","    toktok\n","    transitionparser\n","    treebank\n","    viterbi\n","    weka\n","    wordnet\n","\n","FUNCTIONS\n","    demo()\n","        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n","    \n","    tee(iterable, n=2, /)\n","        Returns a tuple of n independent iterators.\n","\n","DATA\n","    PRETRAINED_TAGGERS = {'eng': 'taggers/averaged_perceptron_tagger_eng/'...\n","    SLASH = *slash*\n","    TYPE = *type*\n","    __author_email__ = 'nltk.team@gmail.com'\n","    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n","    __copyright__ = 'Copyright (C) 2001-2024 NLTK Project.\\n\\nDistribut......\n","    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n","    __license__ = 'Apache License, Version 2.0'\n","    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ...LT...\n","    __maintainer__ = 'NLTK Team'\n","    __maintainer_email__ = 'nltk.team@gmail.com'\n","    __url__ = 'https://www.nltk.org/'\n","    app = <LazyModule 'nltk.app'>\n","    chat = <LazyModule 'nltk.chat'>\n","    corpus = <LazyModule 'nltk.corpus'>\n","    infile = <_io.TextIOWrapper name='/usr/local/lib/python3....packages/n...\n","    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n","    toolbox = <LazyModule 'nltk.toolbox'>\n","    version_file = '/usr/local/lib/python3.10/dist-packages/nltk/VERSION'\n","\n","VERSION\n","    3.9.1\n","\n","AUTHOR\n","    NLTK Team\n","\n","FILE\n","    /usr/local/lib/python3.10/dist-packages/nltk/__init__.py\n","\n","\n"]}]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fj--HUj7PJjo","executionInfo":{"status":"ok","timestamp":1732603932473,"user_tz":-330,"elapsed":533,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"d4e5a515-1bc1-46ec-9289-d19ea36cbb86"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","\n","stopwordss = stopwords.words('english')\n","stopwordss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHLilk-3O4Qb","executionInfo":{"status":"ok","timestamp":1732603936279,"user_tz":-330,"elapsed":593,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"03b5f0fc-4cdb-46fd-ea8b-dee2c5488457"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['i',\n"," 'me',\n"," 'my',\n"," 'myself',\n"," 'we',\n"," 'our',\n"," 'ours',\n"," 'ourselves',\n"," 'you',\n"," \"you're\",\n"," \"you've\",\n"," \"you'll\",\n"," \"you'd\",\n"," 'your',\n"," 'yours',\n"," 'yourself',\n"," 'yourselves',\n"," 'he',\n"," 'him',\n"," 'his',\n"," 'himself',\n"," 'she',\n"," \"she's\",\n"," 'her',\n"," 'hers',\n"," 'herself',\n"," 'it',\n"," \"it's\",\n"," 'its',\n"," 'itself',\n"," 'they',\n"," 'them',\n"," 'their',\n"," 'theirs',\n"," 'themselves',\n"," 'what',\n"," 'which',\n"," 'who',\n"," 'whom',\n"," 'this',\n"," 'that',\n"," \"that'll\",\n"," 'these',\n"," 'those',\n"," 'am',\n"," 'is',\n"," 'are',\n"," 'was',\n"," 'were',\n"," 'be',\n"," 'been',\n"," 'being',\n"," 'have',\n"," 'has',\n"," 'had',\n"," 'having',\n"," 'do',\n"," 'does',\n"," 'did',\n"," 'doing',\n"," 'a',\n"," 'an',\n"," 'the',\n"," 'and',\n"," 'but',\n"," 'if',\n"," 'or',\n"," 'because',\n"," 'as',\n"," 'until',\n"," 'while',\n"," 'of',\n"," 'at',\n"," 'by',\n"," 'for',\n"," 'with',\n"," 'about',\n"," 'against',\n"," 'between',\n"," 'into',\n"," 'through',\n"," 'during',\n"," 'before',\n"," 'after',\n"," 'above',\n"," 'below',\n"," 'to',\n"," 'from',\n"," 'up',\n"," 'down',\n"," 'in',\n"," 'out',\n"," 'on',\n"," 'off',\n"," 'over',\n"," 'under',\n"," 'again',\n"," 'further',\n"," 'then',\n"," 'once',\n"," 'here',\n"," 'there',\n"," 'when',\n"," 'where',\n"," 'why',\n"," 'how',\n"," 'all',\n"," 'any',\n"," 'both',\n"," 'each',\n"," 'few',\n"," 'more',\n"," 'most',\n"," 'other',\n"," 'some',\n"," 'such',\n"," 'no',\n"," 'nor',\n"," 'not',\n"," 'only',\n"," 'own',\n"," 'same',\n"," 'so',\n"," 'than',\n"," 'too',\n"," 'very',\n"," 's',\n"," 't',\n"," 'can',\n"," 'will',\n"," 'just',\n"," 'don',\n"," \"don't\",\n"," 'should',\n"," \"should've\",\n"," 'now',\n"," 'd',\n"," 'll',\n"," 'm',\n"," 'o',\n"," 're',\n"," 've',\n"," 'y',\n"," 'ain',\n"," 'aren',\n"," \"aren't\",\n"," 'couldn',\n"," \"couldn't\",\n"," 'didn',\n"," \"didn't\",\n"," 'doesn',\n"," \"doesn't\",\n"," 'hadn',\n"," \"hadn't\",\n"," 'hasn',\n"," \"hasn't\",\n"," 'haven',\n"," \"haven't\",\n"," 'isn',\n"," \"isn't\",\n"," 'ma',\n"," 'mightn',\n"," \"mightn't\",\n"," 'mustn',\n"," \"mustn't\",\n"," 'needn',\n"," \"needn't\",\n"," 'shan',\n"," \"shan't\",\n"," 'shouldn',\n"," \"shouldn't\",\n"," 'wasn',\n"," \"wasn't\",\n"," 'weren',\n"," \"weren't\",\n"," 'won',\n"," \"won't\",\n"," 'wouldn',\n"," \"wouldn't\"]"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt_tab')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFYuroeMRDCb","executionInfo":{"status":"ok","timestamp":1732604352856,"user_tz":-330,"elapsed":651,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"fcc037a3-78c7-4e7f-b6de-ccee6979f8a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["sentence = \"This is my first sentence. A basic sentence.How are you\"\n","tokens = nltk.word_tokenize(sentence)\n","tokens"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SCvZNgeDPgyC","executionInfo":{"status":"ok","timestamp":1732604356075,"user_tz":-330,"elapsed":593,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"951d5d52-ffb4-4078-dc63-955e4453c22c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['This',\n"," 'is',\n"," 'my',\n"," 'first',\n"," 'sentence',\n"," '.',\n"," 'A',\n"," 'basic',\n"," 'sentence.How',\n"," 'are',\n"," 'you']"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","sentence = \"This is my first sentence. A basic sentence.How are you\"\n","stopwordss = set(stopwords.words('english'))\n","tokens = word_tokenize(sentence)\n","tokens\n","word = [w for w in tokens if not w in stopwordss]\n","word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dj19nB-lRlli","executionInfo":{"status":"ok","timestamp":1732604683053,"user_tz":-330,"elapsed":521,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"e7f391b3-186a-4ff4-9fd6-3ebd2f8e7303"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['This', 'first', 'sentence', '.', 'A', 'basic', 'sentence.How']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","sentence = \"This is my first sentence. A basic sentence.How are you\"\n","stopwordss = set(stopwords.words('english'))\n","tokens = word_tokenize(sentence)\n","tokens\n","word = [w.lower() for w in tokens if not w in stopwordss]\n","word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wb-ykg7_S-mx","executionInfo":{"status":"ok","timestamp":1732604892769,"user_tz":-330,"elapsed":542,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"8d47d7c3-5a23-4057-ba04-b7c05527adb2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['this', 'first', 'sentence', '.', 'a', 'basic', 'sentence.how']"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["#this is not good\n","#this , is , not , good\n","\n","\n","#ngrams\n","\n","#ngrams=1    ngrams=2    ngrams=3\n","# this          this is        this is not\n","\n","#not            not good\n","#good\n"],"metadata":{"id":"V84BXGr0TLE2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from nltk.util import ngrams\n","sentence = \"This is my first sentence. A basic sentence.How are you\"\n","Ngrams = ngrams(sequence = nltk.word_tokenize(sentence), n=3)\n","for grams in Ngrams:\n","  print(grams)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xa-tLvLOUHqL","executionInfo":{"status":"ok","timestamp":1732605313882,"user_tz":-330,"elapsed":701,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"f782de47-9c26-464f-c742-fbe9142e6757"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["('This', 'is', 'my')\n","('is', 'my', 'first')\n","('my', 'first', 'sentence')\n","('first', 'sentence', '.')\n","('sentence', '.', 'A')\n","('.', 'A', 'basic')\n","('A', 'basic', 'sentence.How')\n","('basic', 'sentence.How', 'are')\n","('sentence.How', 'are', 'you')\n"]}]},{"cell_type":"markdown","source":["#Stemming"],"metadata":{"id":"x4W6qNl2S3MX"}},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","sb = SnowballStemmer('english')\n","words = ['This', 'first', 'sentence', '.', 'A', 'basic', 'sentence.How']\n","\n","for w in words:\n","  print(w, \" , \", sb.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uldM7bKNUw-Y","executionInfo":{"status":"ok","timestamp":1732605760984,"user_tz":-330,"elapsed":606,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"ff12d599-37f3-4b04-b08f-08cb32271f91"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This  ,  this\n","first  ,  first\n","sentence  ,  sentenc\n",".  ,  .\n","A  ,  a\n","basic  ,  basic\n","sentence.How  ,  sentence.how\n"]}]},{"cell_type":"code","source":["from nltk.stem import PorterStemmer\n","porter = PorterStemmer()\n","words = ['This', 'first', 'sentence', '.', 'A', 'basic', 'sentence.How']\n","print(\"Word, Porter stem\")\n","for w in words:\n","  print(w, \" , \", porter.stem(w))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-RSXLM0Wy2a","executionInfo":{"status":"ok","timestamp":1732606066965,"user_tz":-330,"elapsed":545,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"205916b3-d1f7-4c85-d57c-08b39f6d2441"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Word, Porter stem\n","This  ,  thi\n","first  ,  first\n","sentence  ,  sentenc\n",".  ,  .\n","A  ,  a\n","basic  ,  basic\n","sentence.How  ,  sentence.how\n"]}]},{"cell_type":"markdown","source":["#Lemmatization"],"metadata":{"id":"pwe50zKoSuz-"}},{"cell_type":"code","source":["import nltk\n","nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywP-If_bZUOj","executionInfo":{"status":"ok","timestamp":1732606517570,"user_tz":-330,"elapsed":782,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"b063a901-0992-4cb6-d08f-18b0d9a969c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","lem = WordNetLemmatizer()\n","print('rocks',lem.lemmatize ('rocks'))\n","print('thought',lem.lemmatize ('thought'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3-3U0BjDXjIX","executionInfo":{"status":"ok","timestamp":1732606523345,"user_tz":-330,"elapsed":5781,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"5401d3d5-4be0-4020-b46a-4328c62625b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks rock\n","thought thought\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","lem = WordNetLemmatizer()\n","#lemmatize as nouns (default behavior)\n","print('rocks',lem.lemmatize ('rocks'))\n","print('thought',lem.lemmatize ('thought'))\n","#lemmatize as verbs\n","print('rocks as verb:',lem.lemmatize ('rocks',pos='v'))\n","print('thought as verb:',lem.lemmatize ('thought',pos='v'))\n","print('played as verb:',lem.lemmatize ('played',pos='v'))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSRqeayQY73n","executionInfo":{"status":"ok","timestamp":1732606736354,"user_tz":-330,"elapsed":574,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"8ff189b8-c39f-447a-ef88-4a82819d3332"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks rock\n","thought thought\n","rocks as verb: rock\n","thought as verb: think\n","played as verb: play\n"]}]},{"cell_type":"code","source":["from nltk.stem import WordNetLemmatizer\n","lem = WordNetLemmatizer()\n","#lemmatize words with different POS tags\n","print('rocks as noun:',lem.lemmatize ('rocks',pos='n'))  #Noun\n","print('rocks as verb:',lem.lemmatize ('rocks',pos='v'))  #Verb\n","print('better as adjective:',lem.lemmatize ('better',pos='a'))  #Adjective\n","print('better as adverb:',lem.lemmatize ('better',pos='r'))  #Adverb\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zFuG2ceaWMz","executionInfo":{"status":"ok","timestamp":1732607086049,"user_tz":-330,"elapsed":610,"user":{"displayName":"fathima nasrin","userId":"04771276345458254442"}},"outputId":"97cc20dc-0a01-4cda-b556-ba1ef5954e40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks as noun: rock\n","rocks as verb: rock\n","better as adjective: good\n","better as adverb: well\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"nveaBFQyS_7e"}}]}